---
title: "Predicting FAANG Stock Prices: A Data-Driven Approach Using Machine Learning Models"
subtitle: "My subtitle if needed"
author: 
  - Jimin (Jamie) Lee
thanks: "Code and data are available at: https://github.com/jamiejiminlee/FAANG-Stock-Forecast.git."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(arrow)
library(kableExtra)
library(xgboost)
library(tidyr)
library(zoo)
library(scales)
library(reshape2)

analysis_data <- read_parquet("/Users/jamielee/TechStockForecast/data/02-analysis_data/analysis_data.parquet")
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}


## Data Overview

This analysis uses historical stock price data for FAANG companies (Meta, Amazon, Apple, Netflix, and Google) obtained from the Yahoo Finance API via the `tidyquant` library in R on November 30, 2024. The dataset spans from January 1, 2020, to December 31, 2024, providing daily records of stock performance, including key metrics such as opening, high, low, and closing prices, trading volume, and adjusted closing prices normalized for corporate actions. To enhance the predictive power of the data, several derived features were constructed. These include lagged adjusted prices to capture sequential trends, daily returns to measure proportional changes, rolling averages to smooth short- and long-term fluctuations, and a rolling standard deviation of prices to quantify market volatility. These features offer a structured framework for identifying patterns and forecasting future stock movements.

The raw data underwent preprocessing to address missing values, particularly for adjusted prices. Missing entries were filled using forward and backward imputation to ensure data continuity. Placeholder dates for December 2024 were interpolated to prepare for out-of-sample predictions. The cleaned dataset, prepared using the `tidyverse`, `lubridate`, `TTR`, and `arrow` libraries, provides a consistent and comprehensive foundation for modeling and analysis.

Further details on the data preparation process are included in [Appendix -@sec-data-cleaning].

## Measurement
Stock price data encapsulates market dynamics influenced by diverse factors, including macroeconomic conditions, corporate events, and investor sentiment. The raw variables in this dataset, such as **`open`**, **`high`**, **`low`**, **`close`**, and **`adjusted`**, capture key price points and provide a snapshot of market activity for each trading day. However, while these variables accurately reflect daily trading outcomes, they may not fully represent intraday fluctuations or complex trading dynamics.

Constructed variables enhance the analytical depth of the dataset by quantifying sequential trends, price variability, and momentum. For instance, **`Lag_1`** captures the adjusted closing price from the previous trading day, providing context for sequential patterns. Variables like **`daily_return`** measure proportional daily changes in price, while moving averages such as **`Rolling_Mean_7`**, **`sma_20`**, and **`sma_50`** smooth short- and long-term price fluctuations, offering a clearer view of overall trends. Additionally, **`volatility`**, computed as the rolling standard deviation of closing prices, quantifies recent price variability and reflects market uncertainty.

Market activity is further contextualized through **`volume`**, representing the total shares traded daily, a proxy for investor interest and liquidity. The inclusion of **`symbol_encoded`**, a numerical encoding of stock tickers, standardizes categorical data for compatibility with machine learning models. Together, these features create a robust framework for analysis, balancing raw price data with derived metrics that highlight market trends and dynamics.

Despite the strengths of these variables, limitations exist. Raw price points do not account for intraday variations, while constructed metrics may oversimplify complex market behaviors. External shocks, such as economic crises or regulatory changes, may not be fully captured within the variables’ scope. Acknowledging these constraints is essential for interpreting the results and understanding the broader context of the analysis. These limitations are further discussed in {@sec-data-details}. 


## Variables

The dataset used for this analysis includes both original and constructed variables, designed to capture temporal trends, volatility, and momentum in stock price movements. Below is a detailed overview of the variables included in the model:

### Original Variables
The original variables directly obtained from the raw stock price data are:

- **`symbol`**: The stock ticker symbol identifying the company (e.g., AAPL for Apple, AMZN for Amazon).
- **`date`**: The trading date, essential for analyzing time-series trends.
- **`open`**: The stock’s opening price for the trading day, indicating initial market conditions.
- **`high`**: The highest price reached during the trading day, reflecting intraday volatility.
- **`low`**: The lowest price during the trading day, reflecting downward market trends.
- **`close`**: The stock’s unadjusted closing price, representing the final value at the end of trading.
- **`volume`**: The total number of shares traded during the day, reflecting market activity.
- **`adjusted`**: The closing price adjusted for corporate actions such as splits or dividends, ensuring consistency for trend analysis.

### Constructed Variables
The constructed variables were engineered to enhance the model's predictive performance by capturing price trends, volatility, and momentum:

- **`Lag_1`**: The closing price from the previous trading day, derived using the `lag()` function. This variable captures sequential patterns in stock prices.
- **`Rolling_Mean_7`**: A 7-day moving average of adjusted closing prices, computed using the `rollmean()` function. This variable smooths short-term fluctuations to highlight weekly trends.
- **`sma_20`**: The 20-day simple moving average (SMA) of adjusted prices, reflecting medium-term price trends.
- **`sma_50`**: The 50-day simple moving average of adjusted prices, providing insights into longer-term trends.
- **`volatility`**: The 20-day rolling standard deviation of adjusted prices, capturing short-term price variability.
- **`daily_return`**: The percentage change in adjusted closing prices relative to the previous day, calculated as:
  $$
  \text{daily_return} = \frac{\text{adjusted}}{\text{Lag_1}} - 1
  $$
  This variable normalizes price changes for comparability across time and stocks.
- **`symbol_encoded`**: A numeric encoding of the stock ticker symbol, allowing the categorical `symbol` variable to be included in the modeling process.

### Outcome Variable
The **outcome variable** for this analysis is the **adjusted closing price (`adjusted`)**, which serves as the target for prediction. This represents the stock's closing price adjusted for corporate actions like stock splits or dividends, providing a normalized measure of stock value. The model aims to predict this variable based on historical data and constructed predictors.


### Predictor Variables
The predictor variables used to model the adjusted closing price are:

- **`Lag_1`**: The prior day's adjusted closing price, reflecting momentum.
- **`Rolling_Mean_7`**: A smoothed metric capturing weekly price trends.
- **`sma_20`** and **`sma_50`**: Simple moving averages representing medium- and long-term price trends.
- **`volatility`**: The short-term price variability, highlighting potential risks.
- **`daily_return`**: The normalized daily percentage price change.
- **`symbol_encoded`**: A numerical representation of the stock ticker symbol, capturing company-level differences.

Together, these variables provide a robust framework for understanding and predicting stock price movements over time, leveraging both raw market indicators and derived metrics.







# Model

## Model Overview

The models in this study forecast the adjusted closing prices of FAANG stocks (Meta, Amazon, Apple, Netflix, and Google) for the months of November and December 2024. Separate models are constructed for each month to capture the time-dependent nature of stock price movements and to account for fluctuations in market conditions leading up to the forecast period. These models utilize a combination of historical stock price data and technical indicators, such as moving averages, volatility, and lagged price features, to estimate future stock prices for each of the five FAANG companies.

To model the changes in stock prices over time, we use features that capture both short-term and long-term market trends. The models incorporate lagged stock prices, 7-day rolling averages, 20-day and 50-day simple moving averages (SMA), daily returns, and volatility indicators. These features are crucial for understanding the patterns and cycles in stock price movements. XGBoost, a powerful machine learning algorithm, is used to build these models, allowing for the capture of non-linear relationships and interactions between the technical indicators and future stock prices.

The training datasets for the November and December models are defined using data up to October 31, 2024, and November 30, 2024, respectively. The models take into account temporal changes in stock prices by using features like lagged prices and rolling averages, which help capture the dynamics of stock price behavior. Additionally, XGBoost's flexibility allows the models to account for varying levels of volatility and market shifts across the different FAANG stocks.

This modeling approach enables the prediction of future stock prices, considering how past price trends and market indicators evolve. By focusing on the November and December timeframes, the models aim to provide forecasts that reflect recent market conditions and predict likely price movements as we approach the end of 2024. The detailed model specifications, including feature selection and hyperparameter tuning, are further discussed in [Appendix -@sec-model-details]

## Model Assumptions

To ensure the validity and reliability of our stock price prediction models, several key assumptions are made during the modeling process. These assumptions are necessary to capture the complexities of stock price behavior while maintaining a clear and interpretable framework for forecasting:

- **Non-Linearity in Price Movements**: Stock prices often exhibit non-linear patterns due to various market forces, including economic news, company performance, and broader market trends. To account for these non-linearities, we use XGBoost, which allows for the modeling of complex, non-linear relationships between the predictors (such as lagged prices and moving averages) and the target variable (adjusted closing prices). This assumption ensures that the model can effectively capture the changing dynamics of stock price movements over time.

- **Stationarity of Price Features**: The model assumes that the selected technical indicators—such as moving averages, volatility, and daily returns—are stationary over the forecasting period. While stock prices are inherently volatile, we assume that the patterns observed in historical data are stable enough to provide reliable predictions for the future months. This assumption allows us to model stock prices without explicitly accounting for trends or seasonality, assuming that the past behavior is a good representation of future dynamics.

- **Independence of Observations**: Each daily stock price observation is assumed to be independent of the others. While stock prices are influenced by previous values (as captured through lagged features), we assume that each day's stock price data point does not directly depend on other data points in ways not captured by the lagged variables or technical indicators. This assumption is important for simplifying the modeling process and ensuring that the features can be treated as independent predictors.

- **Stationarity of Model Parameters**: We assume that the relationships between the stock prices and the chosen technical indicators (e.g., moving averages, volatility) remain relatively stable over the forecast horizon. While stock prices can be influenced by many unpredictable factors, this assumption allows the model to generalize well to the forecasting periods (November and December 2024).

- **Feature Importance**: We assume that the selected features—lagged prices, moving averages, volatility, and daily returns—capture the most important aspects of stock price movements for the FAANG companies. While other factors (such as macroeconomic events, news sentiment, or geopolitical developments) may influence stock prices, these features are chosen for their relevance to technical analysis and their ability to capture short-term and long-term market trends.

- **Use of XGBoost’s Flexibility**: The XGBoost algorithm is assumed to be an appropriate method for this analysis due to its ability to handle large datasets, capture non-linear relationships, and deal with complex interactions between features. We assume that its regularization techniques will help prevent overfitting while still capturing the intricate patterns present in the stock price data.

These assumptions form the foundation of the models and guide the interpretation of the results. While they allow for effective forecasting, it is important to acknowledge that stock price prediction is inherently uncertain, and the accuracy of predictions may vary depending on unforeseen market events and fluctuations.



## Model Setup

Modeling processes are conducted by employing the following packages: `tidyquant` package of @tidyquant for downloading and managing financial data, `xgboost` package of @xgboost for implementing the machine learning model, `dplyr` package of @dplyr for data manipulation, and `lubridate` package of @lubridate for handling dates and times.

### November Model

The primary goal of the November model is to predict the adjusted closing prices of FAANG stocks for the month of November 2024 based on historical stock price data. This model is structured as a regression task using the XGBoost algorithm to estimate the future adjusted closing prices for each of the five FAANG companies.

The model setup can be described as follows:

$$
\hat{y}_{i} = f(X_i)
$$

Where:

- $\hat{y}_i$ is the predicted adjusted closing price for the stock on day $i$.
- $X_i$ represents the feature set for day $i$, which includes:
  - `Lag_1`: The adjusted closing price of the previous day.
  - `Rolling_Mean_7`: The 7-day rolling average of the adjusted closing price.
  - `sma_20`: The 20-day simple moving average.
  - `sma_50`: The 50-day simple moving average.
  - `volatility`: The 14-day rolling standard deviation of daily returns.
  - `daily_return`: The daily percentage change in the adjusted closing price.
  - `symbol_encoded`: A numeric encoding for the FAANG companies (Meta, Amazon, Apple, Netflix, Google).

The dataset for the November model is prepared by extracting the relevant data from January 2020 to October 31, 2024. Features like moving averages and volatility are calculated based on this historical data, and the model is trained to predict the adjusted closing prices for November 2024.

The model was implemented using the **`xgboost`** package in R, which is optimized for performance in regression tasks:

$$
y_i = \text{XGBoost}(X_i, \theta)
$$

Where $y_i$ represents the actual adjusted closing price for day $i$ and $\theta$ represents the model parameters to be learned during training. The model is trained with the following key parameters:
- **Max Depth**: 6
- **Learning Rate**: 0.1
- **Number of Rounds**: 100
- **Objective Function**: Regression with squared error

### December Model

The December model follows a similar approach to the November model, but is trained using data up to November 30, 2024. This ensures that the model accounts for the most recent stock price movements leading up to December, providing a more accurate prediction for the final month of 2024.

The setup for the December model mirrors that of the November model, with the same features and target variable, but applied to the updated dataset. The model structure remains the same, and the XGBoost algorithm is again used for regression:

$$
\hat{y}_{i} = f(X_i)
$$

Where:

- $\hat{y}_i$ is the predicted adjusted closing price for the stock on day $i$ in December 2024.
- $X_i$ includes the same features as the November model, but with data up to November 30, 2024.

The December model is trained using the same XGBoost parameters as the November model. Once trained, the model will generate predictions for December 2024, leveraging the latest market conditions reflected in the training data.

The assumptions and model design are consistent with the November model, with the key differences being the updated data and the forecast period. By training separate models for November and December, we can capture any evolving trends or shifts in stock price behavior as we approach the end of 2024.


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(xgboost)

nov_model <- readRDS("/Users/jamielee/TechStockForecast/models/nov_model.rds")
dec_model <- readRDS("/Users/jamielee/TechStockForecast/models/dec_model.rds")

```



## Model Justification

The XGBoost model is the most suitable approach for forecasting FAANG stock prices in November and December 2024. Our primary outcome variable is the adjusted closing price of each stock, which is continuous and unbounded. XGBoost, a gradient boosting algorithm, excels in handling regression tasks with large datasets, capturing complex, non-linear relationships between features such as lagged prices, moving averages, volatility, and daily returns. To model these relationships effectively, XGBoost's ability to handle feature interactions and non-linearities is key. The inclusion of rolling averages and volatility allows the model to account for both short-term fluctuations and longer-term trends in stock prices, which are often influenced by broader market dynamics. Additionally, the model's flexibility helps capture the intricacies of stock price behavior over time, ensuring that past market patterns are reflected in future predictions.

While simpler models like linear regression could be used, they would fail to capture the complexity and non-linearity inherent in financial data. Machine learning techniques like random forests or support vector machines could also provide robust predictions, but XGBoost’s combination of accuracy, speed, and interpretability makes it the best choice for this analysis. Ultimately, XGBoost’s ability to learn from the data and adjust to market conditions enhances its suitability for predicting FAANG stock prices in an uncertain and volatile market environment.



# Results
```{r}
# Filter November data for prediction
nov_test <- analysis_data %>%
  filter(as.Date(date) >= as.Date("2024-11-01") & as.Date(date) <= as.Date("2024-11-30"))

# Prepare testing features for November
X_test_nov <- nov_test %>%
  select(Lag_1, Rolling_Mean_7, sma_20, sma_50, volatility, daily_return, symbol_encoded) %>%
  as.matrix()

# Predict November prices
dtest_nov <- xgb.DMatrix(data = X_test_nov)
nov_predictions <- predict(nov_model, dtest_nov)

# Combine predictions with actual November data
nov_results <- nov_test %>%
  mutate(predicted_adjusted = nov_predictions) %>%
  select(date, symbol, adjusted, predicted_adjusted)

```

```{r}
# Filter December data for prediction
dec_test <- analysis_data %>%
  filter(as.Date(date) >= as.Date("2024-12-01") & as.Date(date) <= as.Date("2024-12-31"))

# Prepare testing features for December
X_test_dec <- dec_test %>%
  select(Lag_1, Rolling_Mean_7, sma_20, sma_50, volatility, daily_return, symbol_encoded) %>%
  as.matrix()

# Predict December prices
dtest_dec <- xgb.DMatrix(data = X_test_dec)
dec_predictions <- predict(dec_model, dtest_dec)

# Combine predictions with actual December data
dec_results <- dec_test %>%
  mutate(predicted_adjusted = dec_predictions) %>%
  select(date, symbol, predicted_adjusted)

```


## Actual vs Predicted for November 2024
```{r}

# Plot actual vs predicted prices for November 2024
ggplot(nov_results, aes(x = as.Date(date))) +
  geom_line(aes(y = adjusted, color = "Actual"), size = 1) +  # Actual prices
  geom_line(aes(y = predicted_adjusted, color = "Predicted"), linetype = "dashed", size = 1) +  # Predicted prices
  facet_wrap(~symbol, scales = "free_y") +  # Separate panels for each stock
  labs(
    title = "Actual vs Predicted Stock Prices for November 2024",
    x = "Date",
    y = "Stock Price",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +  # Define colors
  theme_minimal() +
  theme(
    legend.position = "bottom",
    text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## Heatmap of Prediction Errors (November 2024)
```{r}
# Add the `error` column to `nov_results`
nov_results <- nov_results %>%
  mutate(error = abs(adjusted - predicted_adjusted))  # Calculate absolute error


# Prepare data for heatmap
nov_heatmap_data <- nov_results %>%
  select(date, symbol, error) %>%
  spread(symbol, error)

# Plot heatmap of prediction errors
ggplot(melt(nov_heatmap_data, id.vars = "date"), aes(x = date, y = variable, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  labs(
    title = "Heatmap of Prediction Errors for November 2024",
    x = "Date",
    y = "Stock Symbol",
    fill = "Error"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 12)
  )
```

## Average Predicted Stock Price - November
```{r}
# Calculate average predicted prices for November
nov_avg_prices <- nov_results %>%
  group_by(symbol) %>%
  summarize(avg_predicted_price = mean(predicted_adjusted, na.rm = TRUE))

# Plot average predicted prices
ggplot(nov_avg_prices, aes(x = symbol, y = avg_predicted_price, fill = symbol)) +
  geom_bar(stat = "identity", width = 0.6) +
  labs(
    title = "Average Predicted Stock Prices for November 2024",
    x = "Stock Symbol",
    y = "Average Predicted Price",
    fill = "Stock Symbol"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_fill_brewer(palette = "Set2")

```



## Predicted Stock Price Trends - December
```{r}
ggplot(dec_results, aes(x = as.Date(date), y = predicted_adjusted, color = symbol)) +
  geom_line(size = 1) +
  labs(
    title = "Predicted Stock Price Trends for December 2024",
    x = "Date",
    y = "Predicted Stock Price",
    color = "Stock Symbol"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## Average Stock Prices Bar Chart - December
```{r}
# Calculate average predicted prices for December
dec_avg_prices <- dec_results %>%
  group_by(symbol) %>%
  summarize(avg_predicted_price = mean(predicted_adjusted, na.rm = TRUE))

# Plot average predicted prices
ggplot(dec_avg_prices, aes(x = symbol, y = avg_predicted_price, fill = symbol)) +
  geom_bar(stat = "identity", width = 0.6) +
  labs(
    title = "Average Predicted Stock Prices for December 2024",
    x = "Stock Symbol",
    y = "Average Predicted Price",
    fill = "Stock Symbol"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_fill_brewer(palette = "Set2")

```

## Average Predicted Stock Price - December

```{r}
# Calculate average predicted price for December
dec_avg_prices <- dec_results %>%
  group_by(symbol) %>%
  summarize(avg_predicted_price = mean(predicted_adjusted, na.rm = TRUE)) %>%
  mutate(avg_predicted_price = dollar(round(avg_predicted_price, 2))) %>%  # Format as dollar and round
  arrange(desc(avg_predicted_price))  # Sort by average price in descending order

# Display the table
dec_avg_prices %>%
  kable(
    caption = "Average Predicted Stock Prices for December 2024",
    col.names = c("Stock Symbol", "Average Predicted Price"),
    format = "markdown"  # Output as markdown for readability
  )
```

## Combined November and December
```{r}
# Combine November and December results
combined_results <- bind_rows(
  nov_results %>% mutate(month = "November"),
  dec_results %>% mutate(month = "December")
)

# Plot predicted prices with facets for each stock
ggplot(combined_results, aes(x = as.Date(date), y = predicted_adjusted, color = month)) +
  geom_line(size = 1) +
  facet_wrap(~symbol, scales = "free_y") +
  labs(
    title = "Predicted Stock Prices for November and December 2024",
    x = "Date",
    y = "Predicted Stock Price",
    color = "Month"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


```


## Average Predicted Stock Prices for November and December 2024

```{r}
# Calculate average predicted prices for November and December
avg_predicted_prices <- combined_results %>%
  group_by(symbol, month) %>%
  summarize(avg_price = mean(predicted_adjusted, na.rm = TRUE), .groups = "drop")

# Reorder the month factor so that "November" comes before "December"
avg_predicted_prices <- avg_predicted_prices %>%
  mutate(month = factor(month, levels = c("November", "December")))

# Plot with the updated order
ggplot(avg_predicted_prices, aes(x = symbol, y = avg_price, fill = month)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("November" = "#F8766D", "December" = "#00BFC4")) +
  labs(
    title = "Average Predicted Stock Prices for November and December 2024",
    x = "Stock Symbol",
    y = "Average Predicted Price (in USD)",
    fill = "Month"
  )
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


