---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}


## Data Overview

This analysis uses historical stock price data for FAANG companies (Meta, Amazon, Apple, Netflix, and Google) obtained from the Yahoo Finance API via the `tidyquant` library in R on November 30, 2024. The dataset spans from January 1, 2020, to December 31, 2024, providing daily records of stock performance, including key metrics such as opening, high, low, and closing prices, trading volume, and adjusted closing prices normalized for corporate actions. To enhance the predictive power of the data, several derived features were constructed. These include lagged adjusted prices to capture sequential trends, daily returns to measure proportional changes, rolling averages to smooth short- and long-term fluctuations, and a rolling standard deviation of prices to quantify market volatility. These features offer a structured framework for identifying patterns and forecasting future stock movements.

The raw data underwent preprocessing to address missing values, particularly for adjusted prices. Missing entries were filled using forward and backward imputation to ensure data continuity. Placeholder dates for December 2024 were interpolated to prepare for out-of-sample predictions. The cleaned dataset, prepared using the `tidyverse`, `lubridate`, `TTR`, and `arrow` libraries, provides a consistent and comprehensive foundation for modeling and analysis.

Further details on the data preparation process are included in [Appendix -@sec-data-cleaning].

## Measurement
Stock price data encapsulates market dynamics influenced by diverse factors, including macroeconomic conditions, corporate events, and investor sentiment. The raw variables in this dataset, such as **`open`**, **`high`**, **`low`**, **`close`**, and **`adjusted`**, capture key price points and provide a snapshot of market activity for each trading day. However, while these variables accurately reflect daily trading outcomes, they may not fully represent intraday fluctuations or complex trading dynamics.

Constructed variables enhance the analytical depth of the dataset by quantifying sequential trends, price variability, and momentum. For instance, **`Lag_1`** captures the adjusted closing price from the previous trading day, providing context for sequential patterns. Variables like **`daily_return`** measure proportional daily changes in price, while moving averages such as **`Rolling_Mean_7`**, **`sma_20`**, and **`sma_50`** smooth short- and long-term price fluctuations, offering a clearer view of overall trends. Additionally, **`volatility`**, computed as the rolling standard deviation of closing prices, quantifies recent price variability and reflects market uncertainty.

Market activity is further contextualized through **`volume`**, representing the total shares traded daily, a proxy for investor interest and liquidity. The inclusion of **`symbol_encoded`**, a numerical encoding of stock tickers, standardizes categorical data for compatibility with machine learning models. Together, these features create a robust framework for analysis, balancing raw price data with derived metrics that highlight market trends and dynamics.

Despite the strengths of these variables, limitations exist. Raw price points do not account for intraday variations, while constructed metrics may oversimplify complex market behaviors. External shocks, such as economic crises or regulatory changes, may not be fully captured within the variables’ scope. Acknowledging these constraints is essential for interpreting the results and understanding the broader context of the analysis. These limitations are further discussed in {@sec-data-details}. 


## Variables

The dataset used for this analysis includes both original and constructed variables, designed to capture temporal trends, volatility, and momentum in stock price movements. Below is a detailed overview of the variables included in the model:

### Original Variables
The original variables directly obtained from the raw stock price data are:

- **`symbol`**: The stock ticker symbol identifying the company (e.g., AAPL for Apple, AMZN for Amazon).
- **`date`**: The trading date, essential for analyzing time-series trends.
- **`open`**: The stock’s opening price for the trading day, indicating initial market conditions.
- **`high`**: The highest price reached during the trading day, reflecting intraday volatility.
- **`low`**: The lowest price during the trading day, reflecting downward market trends.
- **`close`**: The stock’s unadjusted closing price, representing the final value at the end of trading.
- **`volume`**: The total number of shares traded during the day, reflecting market activity.
- **`adjusted`**: The closing price adjusted for corporate actions such as splits or dividends, ensuring consistency for trend analysis.

### Constructed Variables
The constructed variables were engineered to enhance the model's predictive performance by capturing price trends, volatility, and momentum:

- **`Lag_1`**: The closing price from the previous trading day, derived using the `lag()` function. This variable captures sequential patterns in stock prices.
- **`Rolling_Mean_7`**: A 7-day moving average of adjusted closing prices, computed using the `rollmean()` function. This variable smooths short-term fluctuations to highlight weekly trends.
- **`sma_20`**: The 20-day simple moving average (SMA) of adjusted prices, reflecting medium-term price trends.
- **`sma_50`**: The 50-day simple moving average of adjusted prices, providing insights into longer-term trends.
- **`volatility`**: The 20-day rolling standard deviation of adjusted prices, capturing short-term price variability.
- **`daily_return`**: The percentage change in adjusted closing prices relative to the previous day, calculated as:
  $$
  \text{daily_return} = \frac{\text{adjusted}}{\text{Lag_1}} - 1
  $$
  This variable normalizes price changes for comparability across time and stocks.
- **`symbol_encoded`**: A numeric encoding of the stock ticker symbol, allowing the categorical `symbol` variable to be included in the modeling process.

### Outcome Variable
The **outcome variable** for this analysis is the **adjusted closing price (`adjusted`)**, which serves as the target for prediction. This represents the stock's closing price adjusted for corporate actions like stock splits or dividends, providing a normalized measure of stock value. The model aims to predict this variable based on historical data and constructed predictors.


### Predictor Variables
The predictor variables used to model the adjusted closing price are:

- **`Lag_1`**: The prior day's adjusted closing price, reflecting momentum.
- **`Rolling_Mean_7`**: A smoothed metric capturing weekly price trends.
- **`sma_20`** and **`sma_50`**: Simple moving averages representing medium- and long-term price trends.
- **`volatility`**: The short-term price variability, highlighting potential risks.
- **`daily_return`**: The normalized daily percentage price change.
- **`symbol_encoded`**: A numerical representation of the stock ticker symbol, capturing company-level differences.

Together, these variables provide a robust framework for understanding and predicting stock price movements over time, leveraging both raw market indicators and derived metrics.







# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


